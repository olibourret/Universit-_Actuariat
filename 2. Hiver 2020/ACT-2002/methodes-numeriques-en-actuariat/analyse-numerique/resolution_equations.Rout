
R version 3.5.3 (2019-03-11) -- "Great Truth"
Copyright (C) 2019 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin15.6.0 (64-bit)

R est un logiciel libre livré sans AUCUNE GARANTIE.
Vous pouvez le redistribuer sous certaines conditions.
Tapez 'license()' ou 'licence()' pour plus de détails.

R est un projet collaboratif avec de nombreux contributeurs.
Tapez 'contributors()' pour plus d'information et
'citation()' pour la façon de le citer dans les publications.

Tapez 'demo()' pour des démonstrations, 'help()' pour l'aide
en ligne ou 'help.start()' pour obtenir l'aide au format HTML.
Tapez 'q()' pour quitter R.

[Sauvegarde de la session précédente restaurée]

> options(error=expression(NULL))
> ### Emacs: -*- coding: utf-8; fill-column: 62; comment-column: 27; -*-
> ##
> ## Copyright (C) 2018 Vincent Goulet
> ##
> ## Ce fichier fait partie du projet
> ## «Méthodes numériques en actuariat avec R»
> ## https://gitlab.com/vigou3/methodes-numeriques-en-actuariat
> ##
> ## Cette création est mise à disposition sous licence
> ## Attribution-Partage dans les mêmes conditions 4.0
> ## International de Creative Commons.
> ## https://creativecommons.org/licenses/by-sa/4.0/
> 
> ###
> ### MÉTHODE DE BISSECTION  
> ###
> 
> ## Fonction pour trouver la solution de 'FUN'(x) = 0 par la
> ## méthode de bissection, où 'FUN' est une fonction continue
> ## sur l'intervalle ['lower', 'upper'].
> bissection <- function(FUN, lower, upper, TOL = 1E-6,
+                        MAX.ITER = 100, echo = FALSE)
+ {
+     ## Cas triviaux où une borne est la solution
+     if (identical(FUN(lower), 0))
+         return(lower)
+     if (identical(FUN(upper), 0))
+         return(upper)
+ 
+     ## Bornes de départ inadéquates
+     if (FUN(lower) * FUN(upper) > 0)
+         stop('FUN(lower) and FUN(upper) must be of opposite signs')
+ 
+     x <- lower
+     i <- 1
+ 
+     repeat
+     {
+         xt <- x
+         x <- (lower + upper)/2
+         fx <- FUN(x)
+ 
+         if (echo)
+             print(c(lower, upper, x, fx))
+ 
+         if (abs(x - xt)/abs(x) < TOL)
+             break
+ 
+         if (MAX.ITER < (i <- i + 1))
+             stop('Maximum number of iterations reached
+                   without convergence')
+ 
+         if (FUN(lower) * fx > 0)
+             lower <- x
+         else
+             upper <- x
+     }
+     list(root = x, nb.iter = i)
+ }
> 
> ## RACINE D'UN POLYNÔME    
> ##
> ## La fonction dont on cherche la racine
> f <- function(x) x^3 + 4*x^2 - 10
> 
> ## Un graphique de la fonction permet de vérifier qu'elle ne
> ## possède qu'une seule racine sur un intervalle donné ainsi
> ## que des valeurs de départ pour l'algorithme.
> curve(f(x), xlim = c(0, 3), lwd = 2) # graphique sur [0, 3]
> abline(h = 0)                        # axe des abscisses
> 
> ## Résolution. Nous utilisons a = 1 et b = 2 comme valeurs de
> ## départ. Nous pourrions choisir des valeurs de départ plus
> ## près de la racine, ce qui accélèrerait la résolution.
> bissection(f, lower = 1, upper = 2, TOL = 1E-5, echo = TRUE)
[1] 1.000 2.000 1.500 2.375
[1]  1.000000  1.500000  1.250000 -1.796875
[1] 1.2500000 1.5000000 1.3750000 0.1621094
[1]  1.2500000  1.3750000  1.3125000 -0.8483887
[1]  1.3125000  1.3750000  1.3437500 -0.3509827
[1]  1.34375000  1.37500000  1.35937500 -0.09640884
[1] 1.35937500 1.37500000 1.36718750 0.03235579
[1]  1.35937500  1.36718750  1.36328125 -0.03214997
[1] 1.363281e+00 1.367188e+00 1.365234e+00 7.202476e-05
[1]  1.36328125  1.36523438  1.36425781 -0.01604669
[1]  1.364257812  1.365234375  1.364746094 -0.007989263
[1]  1.364746094  1.365234375  1.364990234 -0.003959102
[1]  1.364990234  1.365234375  1.365112305 -0.001943659
[1]  1.3651123047  1.3652343750  1.3651733398 -0.0009358473
[1]  1.3651733398  1.3652343750  1.3652038574 -0.0004319188
[1]  1.3652038574  1.3652343750  1.3652191162 -0.0001799489
[1]  1.365219e+00  1.365234e+00  1.365227e+00 -5.396254e-05
$root
[1] 1.365227

$nb.iter
[1] 17

> 
> ## VALEUR ACTUELLE         
> ##
> ## La fonction dont on cherche la racine
> f <- function(x) (1 - (1 + x)^(-10))/x - 8.2218
> 
> ## Graphique de la fonction sur un intervalle "raisonnable"
> ## dans lequel on peut pressentir que se trouvera la réponse.
> ## Ici, on y va pour un taux d'intérêt se trouvant entre 1 %
> ## et 10 %.
> curve(f(x), xlim = c(0.01, 0.10), lwd = 2)
> abline(h = 0)
> 
> ## Le graphique permet de déterminer à l'oeil que la racine se
> ## trouve entre 3 % et 4 %. Résolution avec la fonction
> ## 'bissection'.
> bissection(f, lower = 0.03, upper = 0.04)
$root
[1] 0.03728109

$nb.iter
[1] 19

> 
> ###
> ### MÉTHODE DU POINT FIXE  
> ###
> 
> ## Fonction pour trouver la solution de 'FUN'(x) = x par la
> ## méthode du point fixe à partir d'un essai initial 'start'.
> pointfixe <- function(FUN, start, TOL = 1E-6, MAX.ITER = 100,
+                       echo = FALSE)
+ {
+     x <- start
+ 
+     if (echo)
+         expr <- expression(print(xt <- x))
+     else
+         expr <- expression(xt <- x)
+ 
+     i <- 0
+ 
+     repeat
+     {
+         eval(expr)
+ 
+         x <- FUN(xt)
+ 
+         if (abs(x - xt)/abs(x) < TOL)
+             break
+ 
+         if (MAX.ITER < (i <- i + 1))
+             stop('Maximum number of iterations reached
+                   without convergence')
+     }
+     list(fixed.point = x, nb.iter = i)
+ }
> 
> ## VALEUR ACTUELLE (bis)   
> ##
> ## La fonction dont on cherche le point fixe.
> g <- function(x) (1 - (1 + x)^(-10))/8.2218
> 
> ## Un graphique de la fonction permet de vérifier que les
> ## conditions pour qu'il existe un point fixe unique dans
> ## l'intervalle [0,035, 0,040] sont satisfaites. Cependant, la
> ## forme de la courbe (pente près de 1) nous indique que la
> ## convergence sera relativement lente.
> f <- function(x) x         # pour tracer la droite y = x
> lim <- c(0.035, 0.040)     # intervalle [a, b]
> curve(g, xlim = lim, ylim = lim, lwd = 2,
+       xlab = "i", ylab = "g(i)")
> curve(f, add = TRUE)
> polygon(rep(lim, each = 2), c(lim, rev(lim)),
+         lty = "dashed", border = "blue")
> 
> ## Résolution avec la fonction 'pointfixe'.
> pointfixe(g, start = 0.0375, echo = TRUE)
[1] 0.0375
[1] 0.03745889
[1] 0.03742554
[1] 0.03739846
[1] 0.03737647
[1] 0.03735861
[1] 0.0373441
[1] 0.03733231
[1] 0.03732273
[1] 0.03731495
[1] 0.03730862
[1] 0.03730347
[1] 0.03729929
[1] 0.03729589
[1] 0.03729312
[1] 0.03729088
[1] 0.03728905
[1] 0.03728756
[1] 0.03728636
[1] 0.03728537
[1] 0.03728457
[1] 0.03728393
[1] 0.0372834
[1] 0.03728297
[1] 0.03728262
[1] 0.03728233
[1] 0.0372821
[1] 0.03728192
[1] 0.03728176
[1] 0.03728164
[1] 0.03728154
[1] 0.03728146
[1] 0.03728139
[1] 0.03728134
[1] 0.03728129
$fixed.point
[1] 0.03728126

$nb.iter
[1] 34

> 
> ## POLYNÔME (bis)          
> ##
> ## Nous cherchons la racine de f(x) = x^3 + 4 * x^2 - 10 en
> ## exprimant le problème sous forme de point fixe. Les cinq
> ## fonctions ci-dessous sont toutes algébriquement
> ## équivalentes, c'est-à-dire que g(x) = x lorsque f(x) = 0.
> g1 <- function(x) x - x^3 - 4 * x^2 + 10
> g2 <- function(x) sqrt(10/x - 4*x)
> g3 <- function(x) sqrt(10 - x^3)/2
> g4 <- function(x) sqrt(10/(4 + x))
> g5 <- function(x) x - (x^3 + 4*x^2 - 10)/(3*x^2 + 8*x)
> 
> ## Si les fonctions sont algébriquement équivalentes, elles ne
> ## le sont pas numériquement devant la méthode du point fixe.
> ## Ainsi, avec la fonction 'g1', la procédure diverge.
> ## (Remarque: la fonction 'poinfixe' ne prévoit pas de message
> ## d'erreur pour ce cas. Qu'ajouteriez-vous à la fonction?)
> pointfixe(g1, 1.5)
Error in if (abs(x - xt)/abs(x) < TOL) break : 
  valeur manquante là où TRUE / FALSE est requis
Calls: pointfixe
> pointfixe(g1, 1.5, echo = TRUE) # plus évident ainsi
[1] 1.5
[1] -0.875
[1] 6.732422
[1] -469.72
[1] 102754555
[1] -1.084934e+24
[1] 1.277056e+72
[1] -2.082713e+216
Error in if (abs(x - xt)/abs(x) < TOL) break : 
  valeur manquante là où TRUE / FALSE est requis
Calls: pointfixe
> 
> ## Avec la fonction 'g2', la procédure s'arrête lorsqu'il faut
> ## calculer la racine carrée d'un nombre négatif.
> pointfixe(g2, 1.5)
Error in if (abs(x - xt)/abs(x) < TOL) break : 
  valeur manquante là où TRUE / FALSE est requis
Calls: pointfixe
De plus : Warning message:
In sqrt(10/x - 4 * x) : production de NaN
> 
> ## Avec les trois autres fonctions, la méthode du point fixe
> ## est extrêmement rapide et précise. Une analyse rapide des 
> ## graphiques fournis dans le chapitre nous permettrait de 
> ## déterminer avec quelle fonction la convergence serait la 
> ## plus rapide. En effet, c'est la fonction 'g5' qui a la
> ## pente la plus faible près de son point fixe.
> pointfixe(g3, 1.5)
$fixed.point
[1] 1.36523

$nb.iter
[1] 18

> pointfixe(g4, 1.5)
$fixed.point
[1] 1.36523

$nb.iter
[1] 6

> pointfixe(g5, 1.5)
$fixed.point
[1] 1.36523

$nb.iter
[1] 3

> 
> ###
> ### MÉTHODE DE NEWTON-RAPHSON  
> ###
> 
> ## Fonction pour trouver la solution de 'FUN'(x) = x par la
> ## méthode de Newton-Raphson à partir de sa dérivée 'FUNp' et
> ## d'un essai initial 'start'.
> ##
> ## On ajoute une amélioration par rapport aux fonctions
> ## 'bissection' et 'pointfixe', soit la possibilité de passer
> ## des arguments additionnels aux fonctions 'FUN' et 'FUNp'
> ## via l'argument '...'
> nr <- function(FUN, FUNp, start, TOL = 1E-6,
+                MAX.ITER = 100, echo = FALSE, ...)
+ {
+     x <- start
+ 
+     if (echo)
+         expr <- expression(print(xt <- x))
+     else
+         expr <- expression(xt <- x)
+ 
+     i <- 0
+ 
+     repeat
+     {
+         eval(expr)
+ 
+         x <- xt - FUN(xt, ...)/FUNp(xt, ...)
+ 
+         if (abs(x - xt)/abs(x) < TOL)
+             break
+ 
+         if (MAX.ITER < (i <- i + 1))
+             stop('Maximum number of iterations reached
+                   without convergence')
+     }
+     list(root = x, nb.iter = i)
+ }
> 
> ## VALEUR ACTUELLE (ter)  
> ##
> ## Nous effectuons de nouveau le calcul d'un taux de
> ## rendement, cette fois avec la méthode de Newton-Raphson. La
> ## convergence devrait être plus rapide qu'avec la méthode du
> ## point fixe puisque la fonction g(i) = i - f(i)/f'(i) est
> ## plus plate que celle utilisée avec la méthode du point
> ## fixe. Premièrement, la fonction dont on cherche la racine.
> f <- function(i) (1 - (1 + i)^(-10))/i - 8.2218
> 
> ## Sa dérivée.
> fp <- function(i) (10 * i * (1 + i)^(-11) + (1 + i)^(-10) - 1)/i^2
> 
> ## Résolution avec la fonction 'nr'.
> nr(f, fp, start = 0.0375, echo = TRUE)
[1] 0.0375
[1] 0.03728092
[1] 0.0372811
$root
[1] 0.0372811

$nb.iter
[1] 2

> 
> ## À noter que si la fonction g est définie adéquatement, nous
> ## pouvons de manière tout aussi équivalente utiliser la
> ## fonction 'pointfixe' pour effectuer les itérations de la
> ## méthode de Newton-Raphson.
> g <- function(i) i - f(i)/fp(i)
> pointfixe(g, 0.0375, echo = TRUE)
[1] 0.0375
[1] 0.03728092
[1] 0.0372811
$fixed.point
[1] 0.0372811

$nb.iter
[1] 2

> 
> ## CAS PATHOLOGIQUE        
> ##
> ## Les fonctions f(x), f'(x) et g(x) définies dans le texte de
> ## l'exemple.
> f <- function(x) ifelse(x == 2, NA, (4 * x - 7)/(x - 2))
> fp <- function(x) ifelse(x == 2, NA, -1/(x - 2)^2)
> g <- function(x) 4 * x^2 - 14 * x + 14
> 
> ## Vérifions que, étant donné la forme des fonctions 'f' et
> ## 'g', la valeur de départ utilisée dans les méthodes de
> ## Newton-Raphson ou du point fixe a un impact sur la réponse
> ## obtenue. Avec une valeur de départ 'start' = 1,625 < 1,75,
> ## la convergence se fait vers la bonne racine.
> nr(f, fp, 1.625, echo = TRUE)
[1] 1.625
[1] 1.8125
[1] 1.765625
[1] 1.750977
[1] 1.750004
[1] 1.75
$root
[1] 1.75

$nb.iter
[1] 5

> pointfixe(g, 1.625)
$fixed.point
[1] 1.75

$nb.iter
[1] 5

> 
> ## Nous pouvons vérifier sur le graphique de la fonction 'g'
> ## qu'avec une valeur de départ entre 1,75 et 2, la procédure
> ## itérative convergera aussi vers la bonne réponse.
> nr(f, fp, 1.875, echo = TRUE)
[1] 1.875
[1] 1.8125
[1] 1.765625
[1] 1.750977
[1] 1.750004
[1] 1.75
$root
[1] 1.75

$nb.iter
[1] 5

> pointfixe(g, 1.875, echo=TRUE)
[1] 1.875
[1] 1.8125
[1] 1.765625
[1] 1.750977
[1] 1.750004
[1] 1.75
$fixed.point
[1] 1.75

$nb.iter
[1] 5

> 
> ## La tangente en x = 1,5 tracée sur le graphique de la
> ## fonction 'f' montre que 'start' = 1,5 constitue un mauvais
> ## choix car g(1,5) = 2. La procédure itérative converge donc
> ## vers une valeur non admissible.
> nr(f, fp, 1.5)             # division par 0
Error in if (abs(x - xt)/abs(x) < TOL) break : 
  valeur manquante là où TRUE / FALSE est requis
Calls: nr
> pointfixe(g, 1.5)          # point fixe non admissible
$fixed.point
[1] 2

$nb.iter
[1] 1

> 
> ## Pour toute valeur de départ supérieure à 2, la procédure
> ## itérative diverge. On peut vérifier ce fait dans les
> ## graphiques de 'f' et de 'g'.
> nr(f, fp, 3, echo = TRUE)
[1] 3
[1] 8
[1] 158
[1] 97658
[1] 38146972658
[1] 5.820766e+21
[1] 1.355253e+44
[1] 7.34684e+88
[1] 2.159042e+178
Error in if (abs(x - xt)/abs(x) < TOL) break : 
  valeur manquante là où TRUE / FALSE est requis
Calls: nr
> pointfixe(g, 3, echo = TRUE)
[1] 3
[1] 8
[1] 158
[1] 97658
[1] 38146972658
[1] 5.820766e+21
[1] 1.355253e+44
[1] 7.34684e+88
[1] 2.159042e+178
Error in if (abs(x - xt)/abs(x) < TOL) break : 
  valeur manquante là où TRUE / FALSE est requis
Calls: pointfixe
> 
> ###
> ### FONCTIONS D'OPTIMISATION DE R  
> ###
> 
> ## FONCTION 'uniroot'
> ##
> ## La fonction 'uniroot' recherche la racine d'une fonction
> ## 'f' dans un intervalle spécifié soit comme une paire de
> ## valeurs dans un argument 'interval', soit via des arguments
> ## 'lower' et 'upper'.
> ##
> ## On calcule la solution de l'équation x - 2^(-x) = 0 dans
> ## l'intervalle [0, 1].
> f <- function(x) x - 2^(-x)      # fonction
> uniroot(f, c(0, 1))              # appel simple
$root
[1] 0.6411922

$f.root
[1] 9.310346e-06

$iter
[1] 3

$init.it
[1] NA

$estim.prec
[1] 6.103516e-05

> uniroot(f, lower = 0, upper = 1) # équivalent
$root
[1] 0.6411922

$f.root
[1] 9.310346e-06

$iter
[1] 3

$init.it
[1] NA

$estim.prec
[1] 6.103516e-05

> 
> ## On peut aussi utiliser 'uniroot' avec une fonction anonyme.
> uniroot(function(x) x - 2^(-x), lower = 0, upper = 1)
$root
[1] 0.6411922

$f.root
[1] 9.310346e-06

$iter
[1] 3

$init.it
[1] NA

$estim.prec
[1] 6.103516e-05

> 
> ## FONCTION 'optimize'
> ##
> ## On cherche le maximum local de la densité d'une loi bêta
> ## dans l'intervalle (0, 1), son domaine de définition. (Ce
> ## problème est facile à résoudre explicitement.)
> ##
> ## Les arguments de 'optimize' sont essentiellement les mêmes
> ## que ceux de 'uniroot'. Ici, on utilise aussi l'argument
> ## '...' pour passer les paramètres de la loi bêta à 'dbeta'.
> ##
> ## Par défaut, la fonction recherche un minimum. Il faut donc
> ## lui indiquer de rechercher plutôt un maximum.
> optimize(dbeta, interval = c(0, 1), maximum = TRUE,
+          shape1 = 3, shape2 = 2)
$maximum
[1] 0.6666795

$objective
[1] 1.777778

> 
> ## On pourrait aussi avoir recours à une fonction auxiliaire.
> ## Moins élégant et moins flexible.
> f <- function(x) dbeta(x, 3, 2)
> optimize(f, lower = 0, upper = 1, maximum = TRUE)
$maximum
[1] 0.6666795

$objective
[1] 1.777778

> 
> ## FONCTION 'nlm'
> ##
> ## Pour la suite, nous allons donner des exemples
> ## d'utilisation des fonctions d'optimisation dans un contexte
> ## d'estimation des paramètres d'une loi gamma par la méthode
> ## du maximum de vraisemblance.
> ##
> ## On commence par se donner un échantillon aléatoire de la
> ## loi. Évidemment, pour ce faire nous devons connaître les
> ## paramètres de la loi. C'est un exemple fictif.
> set.seed(1)                # toujours le même échantillon
> x <- rgamma(10, 5, 2)
> 
> ## Les estimateurs du maximum de vraisemblance des paramètres
> ## 'shape' et 'rate' de la loi gamma sont les valeurs qui
> ## maximisent la fonction de vraisemblance
> ##
> ##     prod(dgamma(x, shape, rate))
> ##
> ## ou, de manière équivalente, qui minimisent la fonction de
> ## log-vraisemblance négative
> ##
> ##     -sum(log(dgamma(x, shape, rate))).
> ##
> ## On remarquera au passage que les fonctions de calcul de
> ## densités de lois de probabilité dans R ont un argument
> ## 'log' qui, lorsque TRUE, retourne la valeur du logarithme
> ## (naturel) de la densité de manière plus précise qu'en
> ## prenant le logarithme après coup. Ainsi, pour faire le
> ## calcul ci-dessus, on optera plutôt, pour l'expression
> ##
> ##     -sum(dgamma(x, shape, rate, log = TRUE))
> ##
> ## La fonction 'nlm' suppose que la fonction à optimiser
> ## passée en premier argument a elle-même comme premier
> ## argument le vecteur 'p' des paramètres à optimiser. Le
> ## second argument de 'nlm' est un vecteur de valeurs de
> ## départ, une pour chaque paramètre.
> ##
> ## Ainsi, pour trouver les estimateurs du maximum de
> ## vraisemblance avec la fonction 'nlm' pour l'échantillon
> ## ci-dessus, on doit d'abord définir une fonction auxiliaire
> ## conforme aux attentes de 'nlm' pour calculer la fonction de
> ## log-vraisemblance (à un signe près).
> f <- function(p, x) -sum(dgamma(x, p[1], p[2], log = TRUE))
> 
> ## L'appel de 'nlm' est ensuite tout simple. Remarquer comment
> ## on passe notre échantillon aléatoire (contenu dans l'objet
> ## 'x') comme second argument à 'f' via l'argument '...' de
> ## 'nlm'. Le fait que l'argument de 'f' et l'objet contenant
> ## les valeurs portent le même nom est sans importance. R sait
> ## faire la différence entre l'un et l'autre.
> nlm(f, c(1, 1), x = x)
$minimum
[1] 13.88354

$estimate
[1] 5.993991 2.382099

$gradient
[1] -2.015223e-08 -2.080533e-07

$code
[1] 1

$iterations
[1] 18

Warning messages:
1: In dgamma(x, p[1], p[2], log = TRUE) : production de NaN
2: In nlm(f, c(1, 1), x = x) :
  NA / Inf remplacé par la valeur maximale positive
3: In dgamma(x, p[1], p[2], log = TRUE) : production de NaN
4: In nlm(f, c(1, 1), x = x) :
  NA / Inf remplacé par la valeur maximale positive
> 
> ## === ASTUCE RIPLEY ===
> ## L'optimisation ci-dessus a généré des avertissements? C'est
> ## parce que la fonction d'optimisation s'est égarée dans les
> ## valeurs négatives, alors que les paramètres d'une gamma
> ## sont strictement positifs. Cela arrive souvent en pratique
> ## et cela peut faire complètement dérailler la procédure
> ## d'optimisation (c'est-à-dire: pas de convergence).
> ##
> ## L'Astuce Ripley consiste à remédier à ce problème en
> ## estimant plutôt les logarithmes des paramètres. Pour ce
> ## faire, il s'agit de réécrire la log-vraisemblance comme une
> ## fonction du logarithme des paramètres, mais de la calculer
> ## avec les véritables paramètres.
> f2 <- function(logp, x)
+ {
+     p <- exp(logp)         # retour aux paramètres originaux
+     -sum(dgamma(x, p[1], p[2], log = TRUE))
+ }
> nlm(f2, c(0, 0), x = x)
$minimum
[1] 13.88354

$estimate
[1] 1.7907530 0.8679778

$gradient
[1] -3.091942e-06  4.344969e-06

$code
[1] 1

$iterations
[1] 13

> 
> ## Les valeurs obtenues ci-dessus sont toutefois les
> ## estimateurs des logarithmes des paramètres de la loi gamma.
> ## On retrouve les estimateurs des paramètres en prenant
> ## l'exponentielle des réponses.
> exp(nlm(f2, c(0, 0), x = x)$estimate)
[1] 5.993964 2.382089
> ## ====================
> 
> ## FONCTION 'nlminb'
> ##
> ## L'utilisation de la fonction 'nlminb' peut s'avérer
> ## intéressante dans notre contexte puisque l'on sait que les
> ## paramètres d'une loi gamma sont strictement positifs.
> nlminb(c(1, 1), f, x = x, lower = 0, upper = Inf)
$par
[1] 5.994063 2.382129

$objective
[1] 13.88354

$convergence
[1] 0

$iterations
[1] 15

$evaluations
function gradient 
      16       38 

$message
[1] "relative convergence (4)"

> 
> ### FONCTION 'optim'
> ##
> ## La fonction 'optim' est très puissante, mais requiert aussi
> ## une bonne dose de prudence. Ses principaux arguments sont:
> ##
> ##  par: un vecteur contenant les valeurs initiales des
> ##       paramètres;
> ##   fn: la fonction à minimiser. Le premier argument de fn
> ##       doit être le vecteur des paramètres.
> ##
> ## Comme pour les autres fonctions étudiées ci-dessus, on peut
> ## passer des arguments à 'fn' (les données, par exemple) par
> ## le biais de l'argument '...' de 'optim'.
> optim(c(1, 1), f, x = x)
$par
[1] 5.995081 2.382622

$value
[1] 13.88354

$counts
function gradient 
      79       NA 

$convergence
[1] 0

$message
NULL

> 
> ## FONCTION 'polyroot'
> ##
> ## Racines du polynôme x^3 + 4 x^2 - 10. Les réponses sont
> ## données sous forme de nombre complexe. Utiliser les
> ## fonctions 'Re' et 'Im' pour extraire les parties réelles et
> ## imaginaires des nombres, respectivement.
> polyroot(c(-10, 0, 4, 1))     # racines
[1]  1.365230-0.000000i -2.682615+0.358259i -2.682615-0.358259i
> Re(polyroot(c(-10, 0, 4, 1))) # parties réelles
[1]  1.365230 -2.682615 -2.682615
> Im(polyroot(c(-10, 0, 4, 1))) # parties imaginaires 
[1] -3.209461e-22  3.582594e-01 -3.582594e-01
> 
